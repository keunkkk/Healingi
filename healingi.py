from fastapi import Request, FastAPI
from openai import OpenAI
import asyncio
import queue as q
import os

client = OpenAI(api_key='')
assistant_id = ''
id_dict = {}
app = FastAPI()

##########ì„œë²„ìƒì„±##########################
@app.get("/")
async def root():
    return {"message": "kakaoTest"}

@app.post("/chat/")
async def chat(request: Request):
    kakaorequest = await request.json()    
    # print('\n\n kakaorequest:', kakaorequest)
    # utterance = kakaorequest["userRequest"]["utterance"]
    # print('utterance:', utterance)
    return await main_chat(kakaorequest)
############################################


async def text_response_format(bot_response):
    print("\n text_response_format start")
    # ì±—ë´‡ ì‘ë‹µì„ ì¹´ì¹´ì˜¤í†¡ í”ŒëŸ¬ìŠ¤ì¹œêµ¬ APIì— ë§ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    response = {'version': '2.0', 'template': {'outputs': [{"simpleText": {"text": bot_response}}], 'quickReplies': []}}
    return response

async def timeover():
    print("\n timeover start")
    response = {"version":"2.0","template":{
      "outputs":[
         {
            "simpleText":{
               "text":"ëŒ€í™”ì¤‘ì— ë¯¸ì•ˆí•´.\nì•„ë˜ ë§í’ì„ ì„ ëˆŒëŸ¬ì¤˜ğŸ‘†"
            }
         }
      ],
      "quickReplies":[
         {
            "action":"message",
            "label":"ë§í’ì„ ğŸˆ",
            "messageText":":)"
         }]}}
    return response


lock = asyncio.Lock()

test = {}

async def get_text_from_gpt(user_id, prompt):
    print("\n get_text_from_gpt start")
    print("\n get_text_from_gpt user_id : ",user_id)
    print(" get_text_from_gpt prompt : ",prompt)
    
    async with lock:
    # ì‚¬ìš©ìë§ˆë‹¤ì˜ ìŠ¤ë ˆë“œ IDë¥¼ ê°€ì ¸ì˜¤ê±°ë‚˜ ìƒì„±
        thread_id = id_dict.get(user_id)

        # ìƒˆë¡œìš´ ì‚¬ìš©ìì¸ ê²½ìš°ì— ëŒ€í•œ ì²˜ë¦¬
        if thread_id is None:
            thread = client.beta.threads.create()
            thread_id = thread.id
            id_dict[user_id] = thread_id

        # ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ OpenAIì— ì „ë‹¬í•˜ê³  ë‹µë³€ì„ ë°›ìŒ
        message = client.beta.threads.messages.create(
            thread_id=thread_id,
            role="user",
            content=prompt
        )

        run = client.beta.threads.runs.create(
            thread_id=thread_id,
            assistant_id=assistant_id,
        )
        while True:
            run = client.beta.threads.runs.retrieve(
                thread_id=thread_id,
                run_id=run.id
            )
            if run.status == "completed":
                break
            else:
                await asyncio.sleep(1)

        # ë‹µë³€ì„ ê°€ì ¸ì˜¤ê¸°
        thread_messages = client.beta.threads.messages.list(thread_id)
        # print(" \n\n thread_messages : ", thread_messages)
        # print(" \n\n result thread_id :", thread_id)
        result = thread_messages.data[0].content[0].text.value 

        print(" gpt result : ", result)
        test[user_id] = result
        print(" gpt test : " , test)
        return result



async def main_chat(kakaorequest):
    # ëŒ€í™” ì‹œì‘ ì‹œê°„ ê¸°ë¡
    start_time = asyncio.get_event_loop().time()
    run_flag = False
    # ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ì„¤ì •    
    cwd = os.getcwd()
    
    # ì‘ë‹µ ê²°ê³¼ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•œ í…ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
    user_id = kakaorequest["userRequest"]["user"]["id"]

    # ì‘ë‹µì„ ì €ì¥í•˜ëŠ” í ìƒì„±
    response_queue = q.Queue()
    
    # OpenAI ë‹µë³€ì„ ì²˜ë¦¬í•˜ëŠ” ë¹„ë™ê¸° ì‘ì—… ìƒì„±
    request_respond = asyncio.create_task(response_openai(kakaorequest, response_queue)) # , filename

    # 3.5ì´ˆ ë™ì•ˆ ëŒ€ê¸°
    while (asyncio.get_event_loop().time() - start_time < 4):
        if not response_queue.empty():
            # 3.5ì´ˆ ì•ˆì— ë‹µë³€ì´ ì™„ì„±ë˜ë©´ ë°”ë¡œ ê°’ ë¦¬í„´
            response = response_queue.get()
            text = response['template']['outputs'][0]['simpleText']['text']

            
            # 3.5ì´ˆ ì•ˆì— ëŒ€ë‹µì´ ì™”ì„ ë•Œ, testì— ì €ì¥ëœ ê°’ ë¹„ì›Œì£¼ê¸°            
            key_to_pop = None
            for key, value in test.items():
                if value == text:
                    key_to_pop = key
                    break            
            if key_to_pop:
                test.pop(key_to_pop)                
            print("\n main_chat after pop test : ", test)
            
            run_flag= True
            break        
            
        await asyncio.sleep(0.1)

    # 3.5ì´ˆ ë‚´ ë‹µë³€ì´ ìƒì„±ë˜ì§€ ì•Šì„ ê²½ìš°
    if run_flag== False:     
        response = await timeover()

    return response

async def response_openai(request, response_queue):  #, filename
    print("\n response_openai start")
    # ì‚¬ìš©ìê°€ ë‹µë³€ í™•ì¸ ë²„íŠ¼ì„ í´ë¦­í•œ ê²½ìš°
    if ':)' in request["userRequest"]["utterance"]:
        user_id = request["userRequest"]["user"]["id"]
        print("\n response user_id = ", user_id)        
        print("\n response test = ", test)
        a = test.pop(user_id, None)
        print("\n response a = ", a)
        
        
        # í…ìŠ¤íŠ¸ íŒŒì¼ ë‚´ ì €ì¥ëœ ì •ë³´ê°€ ìˆì„ ê²½ìš°
        if a == None:
            pass    
        else:
            bot_res = a[0:]
            response_queue.put(await text_response_format(bot_res))
            # dbReset(filename)
    # OpenAIì— ì§ˆë¬¸ì„ ì „ë‹¬í•˜ê³  ì‘ë‹µì„ íì— ì¶”ê°€
    else:       
        prompt = request["userRequest"]["utterance"]
        print("\n response prompt : ", prompt)
        user_id = request["userRequest"]["user"]["id"]
        bot_res = await get_text_from_gpt(user_id, prompt)
        response_queue.put(await text_response_format(bot_res))

    return response_queue